{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam Classifier with Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o53USBMWhsEU"
      },
      "source": [
        "# Build a Spam Classifier with Keras\n",
        "With deep learning and AI, handling spam content has gotten easier and easier. Over time (and with the aid of direct user feedback) or spam classifier will rarely produce erroneous results. \n",
        "\n",
        "\n",
        "### Prerequisites\n",
        "- Prepare your dataset using [this notebook](https://github.com/codingforentrepreneurs/AI-as-an-API/blob/main/guides/spam-classifier/1%20-%20Prepare%20the%20AI%20Spam%20Classifier%20Dataset.ipynb) .\n",
        "- Convert your dataset into trainable vectors in [this notebook](https://github.com/codingforentrepreneurs/AI-as-an-API/blob/main/guides/spam-classifier/2%20-%20Convert%20Dataset%20into%20Vectors.ipynb) (Either way, this notebook will run this step for us).\n",
        "\n",
        "\n",
        "### Running this notebook:\n",
        "- Recommended: Use [Colab](https://colab.research.google.com/github/codingforentrepreneurs/AI-as-an-API/blob/main/guides/spam-classifier/Spam_Classifier_with_Keras.ipynb) as it offers free GPUs for training models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJqrnVLmTxfG"
      },
      "source": [
        "import pathlib\n",
        "import pandas as pd\n",
        "import pickle"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BSsnKlpU_pB"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVD_ZKwBOYSq"
      },
      "source": [
        "EXPORT_DIR = pathlib.Path('/datasets/exports/')\n",
        "GUIDES_DIR = pathlib.Path(\"/guides/spam-classifier/\")\n",
        "DATASET_CSV_PATH = EXPORT_DIR / 'spam-dataset.csv'\n",
        "TRAINING_DATA_PATH = EXPORT_DIR / 'spam-training-data.pkl'\n",
        "PART_TWO_GUIDE_PATH = GUIDES_DIR / \"2 - Convert Dataset into Vectors.ipynb\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZPDBgY4cApj"
      },
      "source": [
        "## Prepare Dataset\n",
        "\n",
        "Creating a dataset rarely happens next to where you run the training. The below cells are a method for us to extract the needed data to perform training against."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1_igE41T2GD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7cc3a39-0d0e-43dc-b0be-9b506ab534ba"
      },
      "source": [
        "!mkdir -p \"$EXPORT_DIR\"\n",
        "!mkdir -p \"$GUIDES_DIR\"\n",
        "!curl \"https://raw.githubusercontent.com/codingforentrepreneurs/AI-as-an-API/main/datasets/exports/spam-dataset.csv\" -o \"$DATASET_CSV_PATH\"\n",
        "!curl \"https://raw.githubusercontent.com/codingforentrepreneurs/AI-as-an-API/main/guides/spam-classifier/2%20-%20Convert%20Dataset%20into%20Vectors.ipynb\" -o \"$PART_TWO_GUIDE_PATH\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  729k  100  729k    0     0  1890k      0 --:--:-- --:--:-- --:--:-- 1890k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 15408  100 15408    0     0  75529      0 --:--:-- --:--:-- --:--:-- 75529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RYybCsJczqn"
      },
      "source": [
        "Let's review our extracted dataset which combines two different spam datasets as outlined in [this notebook](https://github.com/codingforentrepreneurs/AI-as-an-API/blob/main/guides/spam-classifier/1%20-%20Prepare%20the%20AI%20Spam%20Classifier%20Dataset.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OBbbRHAITzq0",
        "outputId": "13b3c966-76a8-40bb-c953-f78e71ccf3ad"
      },
      "source": [
        "df = pd.read_csv(DATASET_CSV_PATH)\n",
        "df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>uci-spam-sms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>uci-spam-sms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>uci-spam-sms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>uci-spam-sms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>uci-spam-sms</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                               text        source\n",
              "0   ham  Go until jurong point, crazy.. Available only ...  uci-spam-sms\n",
              "1   ham                      Ok lar... Joking wif u oni...  uci-spam-sms\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...  uci-spam-sms\n",
              "3   ham  U dun say so early hor... U c already then say...  uci-spam-sms\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...  uci-spam-sms"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWH9NM8KcsSY"
      },
      "source": [
        "In [this notebook](https://github.com/codingforentrepreneurs/AI-as-an-API/blob/main/guides/spam-classifier/2%20-%20Convert%20Dataset%20into%20Vectors.ipynb) we prepare our dataset (`spam-dataset.csv`) to be fully ready for training on a model. Below is a command to run that notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI3KbxGIMNrL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b1f9e9-7b08-43e6-d780-9b8d5d0d0af8"
      },
      "source": [
        "%run \"$PART_TWO_GUIDE_PATH\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASE_DIR is /\n",
            "Random Index 7584\n",
            "Found 9538 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W60Gz74_dB4j"
      },
      "source": [
        "Extract prepared training dataset results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2ABatrpKmW6"
      },
      "source": [
        "data = {}\n",
        "\n",
        "with open(TRAINING_DATA_PATH, 'rb') as f:\n",
        "    data = pickle.load(f)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVcF78xedHkb"
      },
      "source": [
        "> While the above code uses `pickle` to load in data, this data is actually exported via `pickle` when we execute the `%run` only a few steps ago. Since `pickle` can be unsafe to use from third-party downloaded data, we actually generate (again using `%run`) this pickle data and therefore is safe to use -- it's never downloaded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47BJJRESdpV5"
      },
      "source": [
        "## Transform Extracted Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SPvQSPlPFuo"
      },
      "source": [
        "X_test = data['X_test']\n",
        "X_train = data['X_train']\n",
        "y_test = data['y_test']\n",
        "y_train = data['y_train']\n",
        "labels_legend_inverted = data['labels_legend_inverted']\n",
        "legend = data['legend']\n",
        "max_sequence = data['max_sequence']\n",
        "max_words = data['max_words']\n",
        "tokenizer = data['tokenizer']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9S87BLRdvmo"
      },
      "source": [
        "## Create our LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ScyC-JIU81a",
        "outputId": "ce6ac978-dc78-4fd9-cd8c-09375dc00d13"
      },
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NUM_WORDS, embed_dim, input_length=X_train.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.3))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 280, 128)          35840     \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 280, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 394       \n",
            "=================================================================\n",
            "Total params: 291,034\n",
            "Trainable params: 291,034\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liwS1atYVzj0",
        "outputId": "5fb91eff-34cc-4acf-f853-3525dc34a822"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 3\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, verbose=1, epochs=epochs)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "163/163 [==============================] - 319s 2s/step - loss: 0.2540 - accuracy: 0.9015 - val_loss: 0.1307 - val_accuracy: 0.9575\n",
            "Epoch 2/3\n",
            "163/163 [==============================] - 313s 2s/step - loss: 0.1211 - accuracy: 0.9581 - val_loss: 0.1187 - val_accuracy: 0.9633\n",
            "Epoch 3/3\n",
            "163/163 [==============================] - 317s 2s/step - loss: 0.1118 - accuracy: 0.9600 - val_loss: 0.1022 - val_accuracy: 0.9660\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8ee0247910>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VPFG3ZSV3Pr"
      },
      "source": [
        "model.save(str(EXPORT_DIR/'model.h5'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha2sP2r0ebDi"
      },
      "source": [
        "## Predict new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfbt6BQoV6_k"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict(text_str, max_words=280, max_sequence = 280, tokenizer=None):\n",
        "  if not tokenizer:\n",
        "    return None\n",
        "  sequences = tokenizer.texts_to_sequences([text_str])\n",
        "  x_input = pad_sequences(sequences, maxlen=max_sequence)\n",
        "  y_output = model.predict(x_input)\n",
        "  top_y_index = np.argmax(y_output)\n",
        "  preds = y_output[top_y_index]\n",
        "  labeled_preds = [{f\"{labels_legend_inverted[str(i)]}\": x} for i, x in enumerate(preds)]\n",
        "  return labeled_preds"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_Yy6wdXe7R6",
        "outputId": "042e357c-87ae-4f47-e9cb-8876ad6b23dc"
      },
      "source": [
        "predict(\"Hello world\", max_words=max_words, max_sequence=max_sequence, tokenizer=tokenizer)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'ham': 0.9713651}, {'spam': 0.028634934}]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb18jlM9e8nn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}